{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bulk download World Bank Governance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import openpyxl\n",
    "import json\n",
    "import io\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "#logger\n",
    "logging.basicConfig(filename='WB governance.log', filemode='w', format='%(asctime)s - %(message)s', level=logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting country list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for WGI\n",
    "df_countries=pd.read_excel('Countries.xlsx')\n",
    "df_countries=df_countries[(df_countries['Filter']==1)&(df_countries['dataset']=='Governance_dataset')]\n",
    "countries_wgi=dict(zip(df_countries['iso3'],df_countries['Country']))\n",
    "\n",
    "#for ISPAR\n",
    "df_countries=pd.read_excel('Countries.xlsx')\n",
    "df_countries_ispar=df_countries[(df_countries['Filter']==1)&(df_countries['dataset']=='ISPAR')]\n",
    "\n",
    "#for TC360\n",
    "df_countries=pd.read_excel('Countries.xlsx')\n",
    "df_countries=df_countries[(df_countries['Filter']==1)&(df_countries['dataset']=='TCdata360')]\n",
    "countries_tc360=dict(zip(df_countries['iso3'],df_countries['Country']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bulk download from WGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('#############getting data by downloading from https://info.worldbank.org/governance/wgi/#home ##############')\n",
    "\n",
    "url='https://info.worldbank.org/governance/wgi/#home'\n",
    "\n",
    "#get the url for download\n",
    "response=requests.get(url)\n",
    "logging.info(f'request status code for the main url {response.status_code}')\n",
    "soup=BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#getting the href for Download full dataset (Excel) link in the webpage\n",
    "s1=soup.find_all(\"ul\", {\"class\": \"listItems\"})\n",
    "\n",
    "url=s1[1].find_all(\"a\", {\"class\": \"file-download\"})[2]['href']\n",
    "domain='https://info.worldbank.org'\n",
    "#construct the url\n",
    "bulk_download_url=domain+url\n",
    "#to download the url\n",
    "try:\n",
    "    r=requests.get(bulk_download_url)\n",
    "    logging.info(f'Download request is status code is {r.status_code}')\n",
    "except Exception as e:\n",
    "    logging.warning(e)\n",
    "\n",
    "#write the raw data to excel\n",
    "with open('C:/Users/511232/Desktop/Worldwide Governance Indicators/CODES/Datasets/WB governance.xlsx','wb') as f:\n",
    "    try:\n",
    "        f.write(r.content)\n",
    "        logging.info('successfuly downloaded bulk excel file')\n",
    "    except Exception as e:\n",
    "        logging.warning(e)\n",
    "logging.info('---------------------------------------------------')\n",
    "\n",
    "try:\n",
    "    df_WGI=pd.DataFrame()\n",
    "\n",
    "    #get the sheet names to loop over\n",
    "    wb=openpyxl.load_workbook(\"C:/Users/511232/Desktop/Worldwide Governance Indicators/CODES/Datasets/WB governance.xlsx\")\n",
    "    sheetnames=wb.sheetnames[1:]\n",
    "\n",
    "    #counter to count rows of newly added dataframes\n",
    "    sheet_counter={}\n",
    "\n",
    "    for sh in sheetnames:\n",
    "        logging.info(f'processing sheet {sh}')    \n",
    "        df=pd.read_excel('C:/Users/511232/Desktop/Worldwide Governance Indicators/CODES/Datasets/WB governance.xlsx', sheet_name=sh)\n",
    "\n",
    "        #EXTRACT THE DATAFRAME FROM UNSTRCUTURED EXCEL SHEET\n",
    "        #get the dataframe filtered on idx at value = \"Country/Territory\"\n",
    "        idx=df[df.iloc[:,0]==\"Country/Territory\"].index[0]\n",
    "        df1=df.iloc[idx-1:, :].reset_index(drop=True)\n",
    "\n",
    "        #zip the 1st 2 rows to make columns. output example as below\n",
    "        '''((nan, 'Country/Territory'),\n",
    "        (nan, 'Code'),\n",
    "        (1996, 'Estimate'),\n",
    "        (1996, 'StdErr'),\n",
    "        (1996, 'NumSrc'),'''\n",
    "        cols=tuple(zip(df1.iloc[0,:],df1.iloc[1,:]))\n",
    "        #drop the 2 rows\n",
    "        df1.drop(axis=0, index=[0,1], inplace=True)\n",
    "        #add the cols as columns\n",
    "        df1.columns=cols\n",
    "        \n",
    "        #add the sheet name as a column\n",
    "        df1[sh]=sh\n",
    "\n",
    "        #filter the dataframe on ['Country/Territory','Code','Estimate', 'Rank']\n",
    "        cols_to_filter=[(a,b) for (a,b) in list(df1.columns) if (b in ['Country/Territory','Code','Estimate', 'Rank']) | (a==sh)]\n",
    "        #cols_to_filter will look like\n",
    "        '''[(nan, 'Country/Territory'),\n",
    "        (nan, 'Code'),\n",
    "        (1996, 'Estimate'),\n",
    "        (1996, 'Rank'),'''\n",
    "        df1=df1.loc[:,cols_to_filter]\n",
    "\n",
    "        #'Estimate', 'Rank' will be melted, so the melted dataframe must have double the row numbers of the unmelted dataframe. the number of  'Estimate', 'Rank' for timeseries = len(cols_to_filter) - 3 (remove 'Country/Territory','Code', sh)\n",
    "        wide_df_rows= len(df1)\n",
    "        n_wide=len(cols_to_filter)-3\n",
    "\n",
    "        #RESHAPE THE DATAFRAME\n",
    "        #choose 'Country/Territory','Code' and the sheetname col added at the end of the dataframe as id_vars (vars not to be reshaped) and the rest as value_vars (variables to reshape)\n",
    "        # id_variables such as: [(nan, 'Country/Territory'), (nan, 'Code'), (2021, 'Rank')]\n",
    "        id_variables=df1.columns.to_list()[:2]\n",
    "        id_variables.append(df1.columns.to_list()[-1])\n",
    "\n",
    "        df_melt=pd.melt(df1,\n",
    "                id_vars=id_variables,\n",
    "                value_vars=df1.columns.to_list()[2:-1],\n",
    "                var_name=['Year','Value'])\n",
    "                \n",
    "        df_melt.columns=['Country','Code','Indicator','Year','Type','Value']\n",
    "        \n",
    "        #check if melting went ok by checking the number of rows pre and post melting\n",
    "        if len(df_melt)==wide_df_rows*n_wide:\n",
    "            logging.info(f'sheet {sh} succesfully reshaped to long with {len(df_melt)} rows')\n",
    "        else:\n",
    "            logging.warning(f'WARNING!!!!!!!!! problem with melting {sh}, which has {len(df_melt)} rows whereas before melting it had {wide_df_rows} rows and n_wide was {n_wide}')\n",
    "\n",
    "        #APPEND TO Governance_total DATAFRAME\n",
    "        df_WGI=df_WGI.append(df_melt)\n",
    "        logging.info(f'sheet {sh} is appended successfully')\n",
    "        logging.info(f'Governance_total has {len(df_WGI)} rows')\n",
    "        logging.info('---------------------------------------------------------')\n",
    "\n",
    "    #adding the world average\n",
    "    df_WGI['Value']=pd.to_numeric(df_WGI['Value'])\n",
    "    world_avg=df_WGI.groupby(['Indicator', 'Year']).agg({'Value':'mean'}).reset_index()\n",
    "    world_avg['Country']='World'\n",
    "    world_avg\n",
    "    Governance_dataset=pd.concat([df_WGI,world_avg], axis=0)\n",
    "    logging.info('World averages added to the Governance_dataset')\n",
    "\n",
    "    #transforming indicator names\n",
    "    ind_dct={'VoiceandAccountability':'Voice and Accountability',\n",
    "             'Political StabilityNoViolence' : 'Political Stability No Violence',\n",
    "             'GovernmentEffectivenes' : 'Government Effectiveness',\n",
    "             'RegulatoryQuality' : 'Regulatory Quality',\n",
    "             'RuleofLaw' : 'Rule of Law',\n",
    "             'ControlofCorruption' : 'Control of Corruption'}\n",
    "    \n",
    "    df_WGI['Indicator']=df_WGI['Indicator'].map(ind_dct)\n",
    "\n",
    "    df_WGI.to_excel('C:/Users/511232/Desktop/Worldwide Governance Indicators/CODES/Datasets/df_WGI.xlsx', index=False)\n",
    "    logging.info(f'Governance_dataset saved with {len(df_WGI)} rows')\n",
    "\n",
    "    #filter on Arab countries and world\n",
    "    df_WGI_Arab=df_WGI[df_WGI['Country'].isin(countries_wgi.values())].copy()\n",
    "        \n",
    "    #change WBG to PSE for State of Palestine\n",
    "    df_WGI_Arab.loc[df_WGI_Arab['Code']=='WBG', 'Code']='PSE'\n",
    "    logging.info('Code changed from WBG to PSE for State of Palestine')\n",
    "    df_WGI_Arab.loc[df_WGI_Arab['Code']=='PSE', 'Country']='State of Palestine'\n",
    "    logging.info('Country/Territory changed from WBG to PSE for State of Palestine')\n",
    "\n",
    "    #add Note regarding State of Palestine\n",
    "    df_WGI_Arab.loc[df_WGI_Arab['Code']=='PSE', 'Note']='Only for West Bank and Gaza'\n",
    "    logging.info('West bank and Gaza note is added')\n",
    "    \n",
    "    df_WGI_Arab.to_excel('C:/Users/511232/Desktop/Worldwide Governance Indicators/CODES/Datasets/df_WGI_Arab.xlsx', index=False)\n",
    "    logging.info(f'Governance_dataset_Arab saved with {len(df_WGI_Arab)} rows')\n",
    "    logging.info('///////////////////////////////////////////////////////\\n')\n",
    "except Exception as e:\n",
    "    logging.warning(f'!!! WARNING !!! {e}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ISPAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\511232\\Desktop\\Worldwide Governance Indicators\\.WGI\\lib\\site-packages\\pandas\\core\\indexing.py:1599: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = infer_fill_value(value)\n",
      "c:\\Users\\511232\\Desktop\\Worldwide Governance Indicators\\.WGI\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "logging.info('#############getting data from ISPAR##############')\n",
    "\n",
    "id={3:'Global Cybersecurity Index',\n",
    "        4:'Global Gender Gap Index',\n",
    "        5:'ICT Development Index',\n",
    "        6:'Network Readiness Index',\n",
    "        7:'Global Innovation Index',\n",
    "        9:'E-Government Development Index',\n",
    "        11:'Global Competitiveness Index',\n",
    "        12:'E-Participation index',\n",
    "        14:'AI Readiness Index',\n",
    "        16:'Open Data Inventory Index'}\n",
    "\n",
    "url='https://datacatalog.unescwa.org/datastore/dump_v2?resource_id=e0d88222-f90c-4a92-8de4-397f6529c402&format=csv'\n",
    "\n",
    "#get the url for download\n",
    "response=requests.get(url)\n",
    "\n",
    "try:\n",
    "    if response.status_code!=200:\n",
    "        logging.warning(f'!!!!!!WARNING!!!!!!status code is {response.status_code}')\n",
    "\n",
    "    #read the response into pandas dataframe\n",
    "    df = pd.read_csv(io.BytesIO(response.content))\n",
    "    logging.info(f'dataframe returned with {len(df)} rows')\n",
    "\n",
    "    #remove the 0.colname from column names\n",
    "    df.columns=[i.replace(\"0.\", \"\") for i in df.columns]\n",
    "    #save ISPAR_all countries\n",
    "    df.to_excel('ISPAR_all countries.xlsx', index=False)\n",
    "\n",
    "    #filter on Index ID and 'Country Name'\n",
    "    df_ispar_arab=df[(df['Index ID'].isin(id)) & (df['Country Name'].isin(df_countries_ispar['Country']))]\n",
    "\n",
    "    #change PSE to State of Palestine\n",
    "    df_ispar_arab.loc[df_ispar_arab['ISO']=='PSE', 'Country']='State of Palestine'\n",
    "    logging.info('Country changed from West Bank and Gaza to State of Palestine')\n",
    "\n",
    "    #add Note regarding State of Palestine\n",
    "    df_ispar_arab.loc[df_ispar_arab['ISO']=='PSE', 'Note']='Only for West Bank and Gaza'\n",
    "    logging.info('West bank and Gaza note is added')\n",
    "\n",
    "    df_ispar_arab.to_excel('C:/Users/511232/Desktop/Worldwide Governance Indicators/CODES/Datasets/ISPAR_Arab.xlsx', index=False)\n",
    "    logging.info(f'dataframe for Arab countries returned with {len(df_ispar_arab)} rows')\n",
    "\n",
    "    #goupby and aggregate as mean\n",
    "    ispar_aggregated=df_ispar_arab.groupby(['Index Name', 'Year']).aggregate({'Score':'mean'})\n",
    "    ispar_aggregated.to_excel('C:/Users/511232/Desktop/Worldwide Governance Indicators/CODES/Datasets/ISPAR_AGGREGATED.xlsx')\n",
    "    logging.info('groupby.aggregate() successful and saved as ISPAR_AGGREGATED.xlsx')\n",
    "\n",
    "    # #to download to a csv\n",
    "    # with open('ISPAR.csv', 'wb') as f:\n",
    "    #     f.write(response.content)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.warning(f'!!!WARNING!!!  {e}')\n",
    "\n",
    "logging.info('///////////////////////////////////////////////////////\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldbank  TCdata360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    logging.info('#############creating the url for API request for TCdata360##############')\n",
    "\n",
    "    ind_url='https://tcdata360-backend.worldbank.org/api/v1/indicators/'\n",
    "    #get the url for download\n",
    "    response=requests.get(ind_url)\n",
    "    logging.info(f'status code for response ~/api/v1/indicators/ is {response.status_code}')\n",
    "\n",
    "    #get indicator codes to add to the url\n",
    "    df_ind=pd.read_excel('TCdata360_all indicators.xlsx')\n",
    "    df_ind=df_ind[df_ind['Filter']==1]\n",
    "    ind=dict(zip(df_ind['id'],df_ind['name']))\n",
    "\n",
    "    main_data_url='https://tcdata360-backend.worldbank.org/api/v1/data?'\n",
    "\n",
    "    # m_data_url='https://tcdata360-backend.worldbank.org/api/v1/data?countries=ARE%2CBHR%2CCOM%2CDJI%2CDZA%2CEGY%2CIRQ%2CJOR%2CKWT%2CLBN%2CLBY%2CMAR%2CMRT%2COMN%2CQAT%2CSAU%2CSDN%2CSOM%2CSYR%2CTUN%2CYEM%2CPSE&indicators=45410%2C45283%2C3294%2C1776%2C799%2C3500%2C960%2C3421%2C922%2C2073%2C27959%2C27962%2C40712%2C40711'\n",
    "\n",
    "\n",
    "    cntry_url=''\n",
    "    first_element=True\n",
    "    for k,v in countries_tc360.items():\n",
    "        if first_element:\n",
    "            cntry_url=cntry_url+k\n",
    "            first_element=False\n",
    "        else:\n",
    "            cntry_url=cntry_url+'%2C'+k\n",
    "\n",
    "\n",
    "    ind_url=''\n",
    "    first_element=True\n",
    "    for k,v in ind.items():\n",
    "        if first_element:\n",
    "            ind_url=ind_url+str(k)\n",
    "            first_element=False\n",
    "        else:\n",
    "            ind_url=ind_url+'%2C'+str(k)\n",
    "\n",
    "    data_url=main_data_url+'countries='+cntry_url+'&'+'indicators='+ind_url\n",
    "    logging.info(f'data_url constructed as {data_url}')\n",
    "\n",
    "except Exception as e:\n",
    "    logging.warning(f' !!! WARNING !!! {e}')\n",
    "\n",
    "############################################################\n",
    "################get time series data #######################\n",
    "try:\n",
    "    logging.info('#############getting timeseries data for TCdata360##############')\n",
    "    response=requests.get(data_url)\n",
    "    logging.info(f'status code for response ~/api/v1/indicators/ is {response.status_code}')\n",
    "    r=json.loads(response.content)\n",
    "\n",
    "    '''r['data'] is a list of nested dictionaries of the below structure\n",
    "    [{'id': 'DZA',\n",
    "    'indicators': [{'id': 799,\n",
    "        'values': {'1988': 6.3, '1995': 5.6, '2011': 0.4},\n",
    "        'estimated': []}, ...'''\n",
    "\n",
    "    final_data=[]\n",
    "    #looping over each country data\n",
    "    for c in r['data']:\n",
    "        country=c['id']\n",
    "        #looping over data to get metadata\n",
    "        for m in c['indicators']:\n",
    "            metadata=[m['id'],m['estimated']]\n",
    "            metadata.append(country)\n",
    "            #looping over data to get time series values and append to eat list above metadata\n",
    "            country_data=[]\n",
    "            for v in m['values'].items():\n",
    "                datapoint=list(v)\n",
    "                datapoint.extend(metadata)\n",
    "                country_data.append(datapoint)\n",
    "\n",
    "            final_data.extend(country_data)\n",
    "                \n",
    "    df_tc360=pd.DataFrame(final_data,columns=['Year','Value','indicator_id','estimated','Country'])\n",
    "    logging.info(f'dataframe for time series created successfuly with  {len(df_tc360)} rows')\n",
    "\n",
    "    # create a column for indicator name\n",
    "    df_tc360['Indicator_name']=df_tc360['indicator_id'].map(ind)\n",
    "    logging.info('Indicator_name created')\n",
    "    df_tc360['country_name']=df_tc360['Country'].map(countries_tc360)\n",
    "    logging.info('country_name created')\n",
    "    df_tc360.to_excel('C:/Users/511232/Desktop/Worldwide Governance Indicators/CODES/Datasets/TC360_dataset.xlsx',index=False)\n",
    "    logging.info('TC360_data.xlsx saved')\n",
    "\n",
    "except Exception as e:\n",
    "    logging.warning(f' !!! WARNING !!! {e}')\n",
    "\n",
    "logging.info('///////////////////////////////////////////////////////\\n')\n",
    "#######################################################################\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WorldBank WDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    logging.info('Getting WDI data')\n",
    "    #get countries codes to add to the url\n",
    "    df_countries=pd.read_csv('C:/Users/511232/Desktop/Worldwide Governance Indicators/WDI metadata/WDICountry.csv')\n",
    "    df_countries=df_countries[df_countries['Filter']==1].copy()\n",
    "    countries=dict(zip(df_countries['Country Code'],df_countries['Short Name']))\n",
    "\n",
    "    #get indicator codes to add to the url\n",
    "    df_ind=pd.read_csv('C:/Users/511232/Desktop/Worldwide Governance Indicators/WDI metadata/WDISeries.csv')\n",
    "    df_ind=df_ind[df_ind['Filter']==1]\n",
    "    ind=dict(zip(df_ind['Series Code'],df_ind['Indicator Name']))\n",
    "\n",
    "    ########################################\n",
    "    #concatenate the country and series codes\n",
    "    country_codes=''\n",
    "    i=0\n",
    "    for k in countries.keys():\n",
    "        if i==0:\n",
    "            country_codes=country_codes+k\n",
    "            i=1\n",
    "        else:\n",
    "            country_codes=country_codes+';'+k\n",
    "\n",
    "    #############################################\n",
    "    main_url='http://api.worldbank.org/v2/country/'+country_codes+'/indicator/'\n",
    "    # df_WDI=pd.DataFrame()\n",
    "    df_list=[]\n",
    "\n",
    "    for series in ind.keys():\n",
    "        logging.info(f'getting data for series {ind[series]}')\n",
    "        page=1\n",
    "        #loop through pages for each series code\n",
    "        while page:\n",
    "            url=main_url+series+f'?format=json&page={page}'\n",
    "\n",
    "            #get the url for download\n",
    "            response=requests.get(url)\n",
    "\n",
    "            #check if valid data was returned\n",
    "            if len(json.loads(response.content)[1])>0:\n",
    "                #convert to dataframe and append to df_list\n",
    "                df=pd.DataFrame.from_dict(json.loads(response.content)[1], orient='columns')\n",
    "                df_list.append(df)\n",
    "                page+=1\n",
    "                total_pages=page\n",
    "            else:\n",
    "                page=False\n",
    "                logging.info(f'{ind[series]} downloaded with total {total_pages} pages')\n",
    "                logging.info('--------------------------------------')\n",
    "    \n",
    "    #concatenate the dataframes\n",
    "    df_WDI=pd.concat(df_list)\n",
    "    #extract Indicator, Type and Country\n",
    "    df_WDI['Indicator']=df_WDI['indicator'].map(lambda x: x['value'].split(':')[0])\n",
    "\n",
    "    def extract(x):\n",
    "        if len(x['value'].split(':'))>1:\n",
    "            return(x['value'].split(':')[1])\n",
    "        else:\n",
    "            return('')\n",
    "\n",
    "    df_WDI['Type']=df_WDI['indicator'].map(extract)\n",
    "    df_WDI['Country']=df_WDI['country'].map(lambda x: x['value'])\n",
    "    df_WDI.drop(['country', 'indicator'], axis=1, inplace=True)\n",
    "    logging.info('Indicator, Type and Country successfully extracted')\n",
    "\n",
    "    #change PSE to State of Palestine\n",
    "    df_WDI.loc[df_WDI['countryiso3code']=='PSE', 'Country']='State of Palestine'\n",
    "    logging.info('Country changed from West Bank and Gaza to State of Palestine')\n",
    "\n",
    "    #add Note regarding State of Palestine\n",
    "    df_WDI.loc[df_WDI['countryiso3code']=='PSE', 'Note']='Only for West Bank and Gaza'\n",
    "    logging.info('West bank and Gaza note is added')\n",
    "\n",
    "    df_WDI.to_excel('C:/Users/511232/Desktop/Worldwide Governance Indicators/CODES/Datasets/WDI.xlsx')\n",
    "    logging.info('WDI.xlsx saved')\n",
    "\n",
    "except Exception as e:\n",
    "    logging.warning(f'!!! WARNING !!!! {e}')\n",
    "    raise e\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add all the dataframes to a consolidated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the columns to cols_for_consolidated_df\n",
    "cols_for_consolidated_df=[]\n",
    "\n",
    "cols_for_consolidated_df.append(df_WGI_Arab.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the world average\n",
    "Governance_dataset['Value']=pd.to_numeric(Governance_dataset['Value'])\n",
    "world_avg=Governance_dataset.groupby(['Indicator', 'Year']).agg({'Value':'mean'}).reset_index()\n",
    "world_avg['Country']='World'\n",
    "world_avg\n",
    "Governance_dataset=pd.concat([Governance_dataset,world_avg], axis=0)\n",
    "logging.info('World averages added to the Governance_dataset')\n",
    "\n",
    "#change WBG to PSE for State of Palestine\n",
    "# Governance_dataset_Arab.loc[Governance_dataset_Arab['Code']=='WBG', 'Code']='PSE'\n",
    "# logging.info('Code changed from WBG to PSE for State of Palestine')\n",
    "Governance_dataset_Arab.loc[Governance_dataset_Arab['iso3']=='PSE', 'Country']='State of Palestine'\n",
    "logging.info('Country/Territory changed from WBG to PSE for State of Palestine')\n",
    "\n",
    "#add Note regarding State of Palestine\n",
    "Governance_dataset_Arab.loc[Governance_dataset_Arab['iso3']=='PSE', 'Note']='Only for West Bank and Gaza'\n",
    "logging.info('West bank and Gaza note is added')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('gender')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3340a8dbe92e4fa49e59761da80fb0f001258019a079c0e852bc3c4ea6500ccf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

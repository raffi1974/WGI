{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bulk download World Bank Governance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import openpyxl\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logger\n",
    "logging.basicConfig(filename='WB governance.log', filemode='w', format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "url='https://info.worldbank.org/governance/wgi/#home'\n",
    "\n",
    "#get the url for download\n",
    "response=requests.get(url)\n",
    "logging.info(f'request status code for the main url {response.status_code}')\n",
    "soup=BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#getting the href for Download full dataset (Excel) link in the webpage\n",
    "s1=soup.find_all(\"ul\", {\"class\": \"listItems\"})\n",
    "\n",
    "url=s1[1].find_all(\"a\", {\"class\": \"file-download\"})[2]['href']\n",
    "domain='https://info.worldbank.org'\n",
    "#construct the url\n",
    "bulk_download_url=domain+url\n",
    "#to download the url\n",
    "try:\n",
    "    r=requests.get(bulk_download_url)\n",
    "    logging.info(f'Download request is status code is {r.status_code}')\n",
    "except Exception as e:\n",
    "    logging.warning(e)\n",
    "\n",
    "#write the raw data to excel\n",
    "with open('WB governance.xlsx','wb') as f:\n",
    "    try:\n",
    "        f.write(r.content)\n",
    "        logging.info('successfuly downloaded bulk excel file')\n",
    "    except Exception as e:\n",
    "        logging.warning(e)\n",
    "logging.info('#######################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Governance_total=pd.DataFrame()\n",
    "\n",
    "#get the sheet names to loop over\n",
    "wb=openpyxl.load_workbook(\"WB governance.xlsx\")\n",
    "sheetnames=wb.sheetnames[1:]\n",
    "\n",
    "#counter to count rows of newly added dataframes\n",
    "sheet_counter={}\n",
    "\n",
    "for sh in sheetnames:\n",
    "    logging.info(f'processing sheet {sh}')    \n",
    "    df=pd.read_excel('WB governance.xlsx', sheet_name=sh)\n",
    "\n",
    "    #EXTRACT THE DATAFRAME FROM UNSTRCUTURED EXCEL SHEET\n",
    "    #get the dataframe filtered on idx at value = \"Country/Territory\"\n",
    "    idx=df[df.iloc[:,0]==\"Country/Territory\"].index[0]\n",
    "    df1=df.iloc[idx-1:, :].reset_index(drop=True)\n",
    "\n",
    "    #zip the 1st 2 rows to make columns\n",
    "    cols=tuple(zip(df1.iloc[0,:],df1.iloc[1,:]))\n",
    "    #drop the 2 rows\n",
    "    df1.drop(axis=0, index=[0,1], inplace=True)\n",
    "    #add the cols as columns\n",
    "    df1.columns=cols\n",
    "    \n",
    "    #add the sheet name as a column\n",
    "    df1[sh]=sh\n",
    "\n",
    "    #filter the dataframe on ['Country/Territory','Code','Estimate', 'Rank']\n",
    "    cols_to_filter=[(a,b) for (a,b) in list(df1.columns) if (b in ['Country/Territory','Code','Estimate', 'Rank']) | (a==sh)]\n",
    "    df1=df1.loc[:,cols_to_filter]\n",
    "\n",
    "    #'Estimate', 'Rank' will be melted, so the melted dataframe must have double the row numbers of the unmelted dataframe. the number of  'Estimate', 'Rank' for timeseries = len(cols_to_filter) - 2 (remove 'Country/Territory','Code', sh)\n",
    "    wide_df_rows= len(df1)\n",
    "    logging.info(f'wide dataframe for {sh} has {wide_df_rows} rows') \n",
    "    n_wide=len(cols_to_filter)-3\n",
    "\n",
    "    #RESHAPE THE DATAFRAME\n",
    "    #choose 'Country/Territory','Code' and the sheetname col added at the end of the dataframe as id_vars (vars not to be reshaped) and the rest as value_vars (variables to reshape)\n",
    "    id_variables=df1.columns.to_list()[:2]\n",
    "    id_variables.append(df1.columns.to_list()[-1])\n",
    "\n",
    "    df_melt=pd.melt(df1,\n",
    "            id_vars=id_variables,\n",
    "            value_vars=df1.columns.to_list()[2:-1],\n",
    "            var_name=['Year','Type'])\n",
    "            \n",
    "    df_melt.columns=['Country/Territory','Code','Section','Year','Type','value']\n",
    "    \n",
    "    #check if melting went ok by checking the number of rows pre and post melting\n",
    "    if len(df_melt)==wide_df_rows*n_wide:\n",
    "        logging.info(f'sheet {sh} succesfully reshaped to long with {len(df_melt)} rows')\n",
    "    else:\n",
    "        logging.warning(f'WARNING!!!!!!!!! problem with melting {sh}, which has {len(df_melt)} rows whereas before melting it had {wide_df_rows} rows and n_wide was {n_wide}')\n",
    "\n",
    "    #APPEND TO Governance_total DATAFRAME\n",
    "    Governance_total=Governance_total.append(df_melt)\n",
    "    logging.info(f'sheet {sh} is appended successfully')\n",
    "    logging.info(f'Governance_total has {len(Governance_total)} rows')\n",
    "    logging.info('/////////////////////////////////////////////////////')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Governance_total.to_excel('Governance_total.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ISPAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logger\n",
    "logging.basicConfig(filename='ISPAR.log', filemode='w', format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "id={3:'Global Cybersecurity Index',\n",
    "        4:'Global Gender Gap Index',\n",
    "        5:'ICT Development Index',\n",
    "        6:'Network Readiness Index',\n",
    "        7:'Global Innovation Index',\n",
    "        9:'E-Government Development Index',\n",
    "        11:'Global Competitiveness Index',\n",
    "        12:'E-Participation index',\n",
    "        14:'AI Readiness Index',\n",
    "        16:'Open Data Inventory Index'}\n",
    "\n",
    "#get country list\n",
    "country=['Algeria','Bahrain','Comoros','Djibouti','Egypt','Iraq','Jordan','Kuwait','Lebanon','Libya','Morocco','Oman','Qatar','Saudi Arabia','Somalia','State of Palestine','Sudan','Syrian Arab Republic','Tunisia','United Arab Emirates','Yemen, Rep.']\n",
    "\n",
    "url='https://datacatalog.unescwa.org/datastore/dump_v2?resource_id=e0d88222-f90c-4a92-8de4-397f6529c402&format=csv'\n",
    "\n",
    "#get the url for download\n",
    "response=requests.get(url)\n",
    "\n",
    "try:\n",
    "    if response.status_code!=200:\n",
    "        logging.warning(f'!!!!!!WARNING!!!!!!status code is {response.status_code}')\n",
    "\n",
    "    #read the response into pandas dataframe\n",
    "    df = pd.read_csv(io.BytesIO(response.content))\n",
    "    logging.info(f'dataframe returned with {len(df)} rows')\n",
    "\n",
    "    #remove the 0.colname from column names\n",
    "    df.columns=[i.replace(\"0.\", \"\") for i in df.columns]\n",
    "\n",
    "    #filter on Index ID and 'Country Name'\n",
    "    df_filtered=df[(df['Index ID'].isin(id)) & (df['Country Name'].isin(country))]\n",
    "\n",
    "    df_filtered.to_excel('ISPAR.xlsx', index=False)\n",
    "    logging.info(f'dataframe for Arab countries returned with {len(df_filtered)} rows')\n",
    "\n",
    "    #goupby and aggregate as mean\n",
    "    ispar_aggregated=df_filtered.groupby(['Index Name', 'Year']).aggregate({'Score':'mean'})\n",
    "    ispar_aggregated.to_excel('ISPAR_AGGREGATED.xlsx')\n",
    "    logging.info('groupby.aggregate() successful and saved as ISPAR_AGGREGATED.xlsx')\n",
    "\n",
    "    # #to download to a csv\n",
    "    # with open('ISPAR.csv', 'wb') as f:\n",
    "    #     f.write(response.content)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.warning(f'!!!WARNING!!!  {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('gender')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3340a8dbe92e4fa49e59761da80fb0f001258019a079c0e852bc3c4ea6500ccf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bulk download World Bank Governance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import openpyxl\n",
    "import json\n",
    "import io\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "#logger\n",
    "logging.basicConfig(filename='WB governance.log', filemode='w', format='%(asctime)s - %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('#############getting data by downloading from https://info.worldbank.org/governance/wgi/#home ##############')\n",
    "\n",
    "url='https://info.worldbank.org/governance/wgi/#home'\n",
    "\n",
    "#get the url for download\n",
    "response=requests.get(url)\n",
    "logging.info(f'request status code for the main url {response.status_code}')\n",
    "soup=BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#getting the href for Download full dataset (Excel) link in the webpage\n",
    "s1=soup.find_all(\"ul\", {\"class\": \"listItems\"})\n",
    "\n",
    "url=s1[1].find_all(\"a\", {\"class\": \"file-download\"})[2]['href']\n",
    "domain='https://info.worldbank.org'\n",
    "#construct the url\n",
    "bulk_download_url=domain+url\n",
    "#to download the url\n",
    "try:\n",
    "    r=requests.get(bulk_download_url)\n",
    "    logging.info(f'Download request is status code is {r.status_code}')\n",
    "except Exception as e:\n",
    "    logging.warning(e)\n",
    "\n",
    "#write the raw data to excel\n",
    "with open('WB governance.xlsx','wb') as f:\n",
    "    try:\n",
    "        f.write(r.content)\n",
    "        logging.info('successfuly downloaded bulk excel file')\n",
    "    except Exception as e:\n",
    "        logging.warning(e)\n",
    "logging.info('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-0f6fb0346ecd>:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Governance_dataset_Arab['Code']=Governance_dataset_Arab['Code'].map({'WBG':'PSE'})\n"
     ]
    }
   ],
   "source": [
    "Governance_dataset=pd.DataFrame()\n",
    "\n",
    "#get the sheet names to loop over\n",
    "wb=openpyxl.load_workbook(\"WB governance.xlsx\")\n",
    "sheetnames=wb.sheetnames[1:]\n",
    "\n",
    "#counter to count rows of newly added dataframes\n",
    "sheet_counter={}\n",
    "\n",
    "for sh in sheetnames:\n",
    "    logging.info(f'processing sheet {sh}')    \n",
    "    df=pd.read_excel('WB governance.xlsx', sheet_name=sh)\n",
    "\n",
    "    #EXTRACT THE DATAFRAME FROM UNSTRCUTURED EXCEL SHEET\n",
    "    #get the dataframe filtered on idx at value = \"Country/Territory\"\n",
    "    idx=df[df.iloc[:,0]==\"Country/Territory\"].index[0]\n",
    "    df1=df.iloc[idx-1:, :].reset_index(drop=True)\n",
    "\n",
    "    #zip the 1st 2 rows to make columns\n",
    "    cols=tuple(zip(df1.iloc[0,:],df1.iloc[1,:]))\n",
    "    #drop the 2 rows\n",
    "    df1.drop(axis=0, index=[0,1], inplace=True)\n",
    "    #add the cols as columns\n",
    "    df1.columns=cols\n",
    "    \n",
    "    #add the sheet name as a column\n",
    "    df1[sh]=sh\n",
    "\n",
    "    #filter the dataframe on ['Country/Territory','Code','Estimate', 'Rank']\n",
    "    cols_to_filter=[(a,b) for (a,b) in list(df1.columns) if (b in ['Country/Territory','Code','Estimate', 'Rank']) | (a==sh)]\n",
    "    df1=df1.loc[:,cols_to_filter]\n",
    "\n",
    "    #'Estimate', 'Rank' will be melted, so the melted dataframe must have double the row numbers of the unmelted dataframe. the number of  'Estimate', 'Rank' for timeseries = len(cols_to_filter) - 2 (remove 'Country/Territory','Code', sh)\n",
    "    wide_df_rows= len(df1)\n",
    "    logging.info(f'wide dataframe for {sh} has {wide_df_rows} rows') \n",
    "    n_wide=len(cols_to_filter)-3\n",
    "\n",
    "    #RESHAPE THE DATAFRAME\n",
    "    #choose 'Country/Territory','Code' and the sheetname col added at the end of the dataframe as id_vars (vars not to be reshaped) and the rest as value_vars (variables to reshape)\n",
    "    id_variables=df1.columns.to_list()[:2]\n",
    "    id_variables.append(df1.columns.to_list()[-1])\n",
    "\n",
    "    df_melt=pd.melt(df1,\n",
    "            id_vars=id_variables,\n",
    "            value_vars=df1.columns.to_list()[2:-1],\n",
    "            var_name=['Year','Type'])\n",
    "            \n",
    "    df_melt.columns=['Country/Territory','Code','Section','Year','Type','value']\n",
    "    \n",
    "    #check if melting went ok by checking the number of rows pre and post melting\n",
    "    if len(df_melt)==wide_df_rows*n_wide:\n",
    "        logging.info(f'sheet {sh} succesfully reshaped to long with {len(df_melt)} rows')\n",
    "    else:\n",
    "        logging.warning(f'WARNING!!!!!!!!! problem with melting {sh}, which has {len(df_melt)} rows whereas before melting it had {wide_df_rows} rows and n_wide was {n_wide}')\n",
    "\n",
    "    #APPEND TO Governance_total DATAFRAME\n",
    "    Governance_dataset=Governance_dataset.append(df_melt)\n",
    "    logging.info(f'sheet {sh} is appended successfully')\n",
    "    logging.info(f'Governance_total has {len(Governance_dataset)} rows')\n",
    "    logging.info('---------------------------------------------------------')\n",
    "\n",
    "Governance_dataset.to_excel('Governance_dataset.xlsx', index=False)\n",
    "logging.info(f'Governance_dataset saved with {len(Governance_dataset)} rows')\n",
    "\n",
    "#get countries codes\n",
    "df_countries=pd.read_excel('Countries.xlsx')\n",
    "df_countries=df_countries[(df_countries['Filter']==1)&(df_countries['dataset']=='Governance_dataset')]\n",
    "countries=dict(zip(df_countries['iso3'],df_countries['Country']))\n",
    "\n",
    "#filter on Arab countries\n",
    "Governance_dataset_Arab=Governance_dataset[Governance_dataset['Country/Territory'].isin(countries.values())]\n",
    "Governance_dataset_Arab.to_excel('Governance_dataset_Arab.xlsx', index=False)\n",
    "logging.info(f'Governance_dataset_Arab saved with {len(Governance_dataset_Arab)} rows')\n",
    "\n",
    "#change the code of West Bank and Gaza from WBG to PSE for State of Palestine\n",
    "Governance_dataset_Arab['Code']=Governance_dataset_Arab['Code'].map({'WBG':'PSE'})\n",
    "logging.info(f'{len(Governance_dataset_Arab[\"Code\"][Governance_dataset_Arab[\"Code\"]==\"PSE\"])} labels were changed from WBG to PSE')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ISPAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('#############getting data from ISPAR##############')\n",
    "\n",
    "id={3:'Global Cybersecurity Index',\n",
    "        4:'Global Gender Gap Index',\n",
    "        5:'ICT Development Index',\n",
    "        6:'Network Readiness Index',\n",
    "        7:'Global Innovation Index',\n",
    "        9:'E-Government Development Index',\n",
    "        11:'Global Competitiveness Index',\n",
    "        12:'E-Participation index',\n",
    "        14:'AI Readiness Index',\n",
    "        16:'Open Data Inventory Index'}\n",
    "\n",
    "\n",
    "#get countries codes to add to the url\n",
    "df_countries=pd.read_excel('Countries.xlsx')\n",
    "df_countries=df_countries[(df_countries['Filter']==1)&(df_countries['dataset']=='ISPAR')]\n",
    "# countries=dict(zip(df_countries['iso3'],df_countries['Country']))\n",
    "\n",
    "url='https://datacatalog.unescwa.org/datastore/dump_v2?resource_id=e0d88222-f90c-4a92-8de4-397f6529c402&format=csv'\n",
    "\n",
    "#get the url for download\n",
    "response=requests.get(url)\n",
    "\n",
    "try:\n",
    "    if response.status_code!=200:\n",
    "        logging.warning(f'!!!!!!WARNING!!!!!!status code is {response.status_code}')\n",
    "\n",
    "    #read the response into pandas dataframe\n",
    "    df = pd.read_csv(io.BytesIO(response.content))\n",
    "    logging.info(f'dataframe returned with {len(df)} rows')\n",
    "\n",
    "    #remove the 0.colname from column names\n",
    "    df.columns=[i.replace(\"0.\", \"\") for i in df.columns]\n",
    "\n",
    "    #filter on Index ID and 'Country Name'\n",
    "    df_filtered=df[(df['Index ID'].isin(id)) & (df['Country Name'].isin(df_countries['Country']))]\n",
    "\n",
    "    df_filtered.to_excel('ISPAR_dataset.xlsx', index=False)\n",
    "    logging.info(f'dataframe for Arab countries returned with {len(df_filtered)} rows')\n",
    "\n",
    "    #goupby and aggregate as mean\n",
    "    ispar_aggregated=df_filtered.groupby(['Index Name', 'Year']).aggregate({'Score':'mean'})\n",
    "    ispar_aggregated.to_excel('ISPAR_AGGREGATED.xlsx')\n",
    "    logging.info('groupby.aggregate() successful and saved as ISPAR_AGGREGATED.xlsx')\n",
    "\n",
    "    # #to download to a csv\n",
    "    # with open('ISPAR.csv', 'wb') as f:\n",
    "    #     f.write(response.content)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.warning(f'!!!WARNING!!!  {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldbank  TCdata360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    logging.info('#############creating the url for API request for TCdata360##############')\n",
    "\n",
    "    ind_url='https://tcdata360-backend.worldbank.org/api/v1/indicators/'\n",
    "    #get the url for download\n",
    "    response=requests.get(ind_url)\n",
    "    logging.info(f'status code for response ~/api/v1/indicators/ is {response.status_code}')\n",
    "\n",
    "    #get countries codes to add to the url\n",
    "    df_countries=pd.read_excel('Countries.xlsx')\n",
    "    df_countries=df_countries[(df_countries['Filter']==1)&(df_countries['dataset']=='TCdata360')]\n",
    "    countries=dict(zip(df_countries['iso3'],df_countries['Country']))\n",
    "\n",
    "    #get indicator codes to add to the url\n",
    "    df_ind=pd.read_excel('indicators_TC360.xlsx')\n",
    "    df_ind=df_ind[df_ind['Filter']==1]\n",
    "    ind=dict(zip(df_ind['id'],df_ind['name']))\n",
    "\n",
    "    main_data_url='https://tcdata360-backend.worldbank.org/api/v1/data?'\n",
    "\n",
    "    # m_data_url='https://tcdata360-backend.worldbank.org/api/v1/data?countries=ARE%2CBHR%2CCOM%2CDJI%2CDZA%2CEGY%2CIRQ%2CJOR%2CKWT%2CLBN%2CLBY%2CMAR%2CMRT%2COMN%2CQAT%2CSAU%2CSDN%2CSOM%2CSYR%2CTUN%2CYEM%2CPSE&indicators=45410%2C45283%2C3294%2C1776%2C799%2C3500%2C960%2C3421%2C922%2C2073%2C27959%2C27962%2C40712%2C40711'\n",
    "\n",
    "    cntry_url=''\n",
    "    first_element=True\n",
    "    for k,v in countries.items():\n",
    "        if first_element:\n",
    "            cntry_url=cntry_url+k\n",
    "            first_element=False\n",
    "        else:\n",
    "            cntry_url=cntry_url+'%2C'+k\n",
    "\n",
    "\n",
    "    ind_url=''\n",
    "    first_element=True\n",
    "    for k,v in ind.items():\n",
    "        if first_element:\n",
    "            ind_url=ind_url+str(k)\n",
    "            first_element=False\n",
    "        else:\n",
    "            ind_url=ind_url+'%2C'+str(k)\n",
    "\n",
    "    data_url=main_data_url+'countries='+cntry_url+'&'+'indicators='+ind_url\n",
    "    logging.info(f'data_url constructed as {data_url}')\n",
    "\n",
    "except Exception as e:\n",
    "    logging.warning(f' !!! WARNING !!! {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################get time series data #######################\n",
    "try:\n",
    "    logging.info('#############getting timeseries data for TCdata360##############')\n",
    "    response=requests.get(data_url)\n",
    "    logging.info(f'status code for response ~/api/v1/indicators/ is {response.status_code}')\n",
    "    r=json.loads(response.content)\n",
    "\n",
    "    '''r['data'] is a list of nested dictionaries of the below structure\n",
    "    [{'id': 'DZA',\n",
    "    'indicators': [{'id': 799,\n",
    "        'values': {'1988': 6.3, '1995': 5.6, '2011': 0.4},\n",
    "        'estimated': []}, ...'''\n",
    "\n",
    "    final_data=[]\n",
    "    #looping over each country data\n",
    "    for c in r['data']:\n",
    "        country=c['id']\n",
    "        #looping over data to get metadata\n",
    "        for m in c['indicators']:\n",
    "            metadata=[m['id'],m['estimated']]\n",
    "            metadata.append(country)\n",
    "            #looping over data to get time series values and append to eat list above metadata\n",
    "            country_data=[]\n",
    "            for v in m['values'].items():\n",
    "                datapoint=list(v)\n",
    "                datapoint.extend(metadata)\n",
    "                country_data.append(datapoint)\n",
    "\n",
    "            final_data.extend(country_data)\n",
    "                \n",
    "    final_data_df=pd.DataFrame(final_data,columns=['Year','Value','indicator_id','estimated','Country'])\n",
    "    logging.info(f'dataframe for time series created successfuly with  {len(final_data_df)} rows')\n",
    "\n",
    "    # create a column for indicator name\n",
    "    final_data_df['Indicator_name']=final_data_df['indicator_id'].map(ind)\n",
    "    logging.info('Indicator_name created')\n",
    "    final_data_df['country_name']=final_data_df['Country'].map(countries)\n",
    "    logging.info('country_name created')\n",
    "    final_data_df.to_excel('TC360_dataset.xlsx',index=False)\n",
    "    logging.info('TC360_data.xlsx saved')\n",
    "\n",
    "except Exception as e:\n",
    "    logging.warning(f' !!! WARNING !!! {e}')\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WorldBank WDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get countries codes to add to the url\n",
    "df_countries=pd.read_csv('C:/Users/511232/Desktop/Worldwide Governance Indicators/WDI metadata/WDICountry.csv')\n",
    "df_countries=df_countries[df_countries['Filter']==1].copy()\n",
    "countries=dict(zip(df_countries['Country Code'],df_countries['Short Name']))\n",
    "\n",
    "#get indicator codes to add to the url\n",
    "df_ind=pd.read_csv('C:/Users/511232/Desktop/Worldwide Governance Indicators/WDI metadata/WDISeries.csv')\n",
    "df_ind=df_ind[df_ind['Filter']==1]\n",
    "ind=dict(zip(df_ind['Series Code'],df_ind['Indicator Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the country and series codes\n",
    "country_codes=''\n",
    "i=0\n",
    "for k in countries.keys():\n",
    "    if i==0:\n",
    "        country_codes=country_codes+k\n",
    "        i=1\n",
    "    else:\n",
    "        country_codes=country_codes+';'+k\n",
    "\n",
    "series_codes=''\n",
    "i=0\n",
    "for k in ind.keys():\n",
    "    if i==0:\n",
    "        series_codes=series_codes+k\n",
    "        i=1\n",
    "    else:\n",
    "        series_codes=series_codes+';'+k\n",
    "\n",
    "page=1\n",
    "url='http://api.worldbank.org/v2/country/'+country_codes+'/indicator/'+series_codes+f'?format=json&page={page}'\n",
    "\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'message': [{'id': '120',\n",
       "    'key': 'Invalid value',\n",
       "    'value': 'The provided parameter value is not valid'}]}]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logging.info('#############creating the url for API request for WDI##############')\n",
    "ind_url=url\n",
    "#get the url for download\n",
    "response=requests.get(ind_url)\n",
    "print(response.status_code)\n",
    "\n",
    "json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(json.loads(response.content)[1], orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'message': [{'id': '120',\n",
       "    'key': 'Invalid value',\n",
       "    'value': 'The provided parameter value is not valid'}]}]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='http://api.worldbank.org/v2/country/ARB;ARE/indicator/CC.EST;DT.DOD.DECT.GN.ZS?format=json&page=1'\n",
    "''\n",
    "ind_url=url\n",
    "#get the url for download\n",
    "response=requests.get(ind_url)\n",
    "print(response.status_code)\n",
    "\n",
    "json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('gender')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3340a8dbe92e4fa49e59761da80fb0f001258019a079c0e852bc3c4ea6500ccf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
